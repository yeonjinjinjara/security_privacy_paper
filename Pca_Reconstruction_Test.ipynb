{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8deafdce-54a4-432c-98ad-8212e9a11799",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb9b23d6-d092-474a-b1ab-561c3f4cccdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_dataset(files, col_names, processed = False):\n",
    "\tdtypes = {}\n",
    "\tif processed == False:\n",
    "\t\tfor col_name in col_names:\n",
    "\t\t\tnominal_names = set(['srcip', 'sport', 'dstip', 'dsport', 'proto', 'state',\n",
    "\t\t\t\t                 'service', 'ct_ftp', 'label_10'])  #Nominal column\n",
    "\t\t\tif col_name in nominal_names:\n",
    "\t\t\t\tdtypes[col_name] =  str\n",
    "\t\t\telse:\n",
    "\t\t\t\tdtypes[col_name] = np.float32\n",
    "\telse:\n",
    "\t\tfor col_name in col_names:\n",
    "\t\t\tdtypes[col_name] = np.float32\n",
    "\n",
    "\trecords = []\n",
    "\tfor file in files:\n",
    "\t\tdata = pd.read_csv(file, header = None, names = col_names, dtype = dtypes)\n",
    "\t\trecords.append(data)\n",
    "\n",
    "\trecords_all = pd.concat(records) #When there is no index, concat adds them together regardless of the column names,\n",
    "\n",
    "\n",
    "\treturn records_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "491a306f-712b-48d1-bbde-208a1e7e5026",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove the unimportant feature, one-hot encoding, and convert the attack class to numeric\n",
    "def select_feature_and_encoding(dataset, cols_to_drop, cols_nominal):\n",
    "    \n",
    "\t# Drop the features has no meaning such as src ip.\n",
    "    for cols in cols_to_drop:\n",
    "        dataset.drop(cols, axis = 1, inplace = True)\n",
    "\n",
    "\t# Save the label and then drop it from dataset\n",
    "    label_10 = dataset['label_10']\n",
    "    dataset.drop('label_2', axis = 1, inplace = True)\n",
    "\n",
    "\t# replace the label with specific code\n",
    "    replace_dict = { 'NaN': 0, 'Analysis': 1, 'Backdoors': 2, 'Backdoor': 2, 'DoS': 3,\n",
    "                    'Exploits':4,' Fuzzers': 5, ' Fuzzers ':5, 'Generic': 6,\n",
    "                    'Reconnaissance': 7, ' Shellcode ':8, 'Shellcode': 8,\n",
    "                    'Worms':9, ' Reconnaissance ': 7,}\n",
    "    dataset['label_10'] = label_10.replace(replace_dict)\n",
    "\n",
    "\t# replace the lost values\n",
    "    replace_dict = {\"NaN\": 0, ' ': 0}\n",
    "    for cols in ['ct_ftp', 'ct_flw', 'is_ftp']:\n",
    "        dataset[cols] = dataset[cols].replace(replace_dict)\n",
    "        \n",
    "    for x in dataset['is_ftp']:\n",
    "        if x != 0:\n",
    "            x = 1\n",
    "\n",
    "    for col_name in cols_nominal:\n",
    "        dataset.drop(col_name, axis = 1, inplace = True) \n",
    "\n",
    "    return dataset  #Complete data set (including data and labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3ef8e30-d46e-48a5-8781-5c33df805168",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_folder = 'unsw-NB15/'  #The location where the original file was read\n",
    "col_names = ['srcip', 'sport', 'dstip', 'dsport', 'proto', 'state', 'dur',\n",
    "\t             'sbytes', 'dbytes', 'sttl', 'dttl', 'sloss', 'dloss',\n",
    "\t             'service', 'sload', 'dload', 'spkts', 'dpkts', 'swin', 'dwin',\n",
    "\t             'stcpb', 'dtcpb', 'smeansz', 'dmeansz', 'trans_depth',\n",
    "\t             'res_bdy_len', 'sjit', 'djit', 'stime', 'ltime', 'sintpkt',\n",
    "\t             'dintpkt', 'tcprtt', 'synack', 'ackdat', 'is_sm_ips',\n",
    "\t             'ct_state_ttl', 'ct_flw', 'is_ftp', 'ct_ftp', 'ct_srv_src',\n",
    "\t             'ct_srv_dst', 'ct_dst_ltm', 'ct_src_ltm', 'ct_src_dport',\n",
    "\t             'ct_dst_sport', 'ct_dst_src', 'label_10', 'label_2']    #listed name\n",
    "\n",
    "cols_to_drop = ['srcip', 'dstip', 'stime', 'ltime', 'sport', 'dsport']\n",
    "cols_nominal = ['proto', 'service', 'state']   #Nominal features\n",
    "\n",
    "files = [file_folder + 'UNSW-NB15_' + str(i+1) + '.csv' for i in range(4)]\n",
    "dataset = combine_dataset(files, col_names)\n",
    "dataset = dataset.fillna(\"NaN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "594cb37d-a033-4235-9fa5-812b98a99194",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = select_feature_and_encoding(dataset, cols_to_drop, cols_nominal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aba0003d-842f-4997-9050-9a3db6c919d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.drop('label_10', axis=1) \n",
    "y = dataset['label_10'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "261c5d17-2704-4b2f-9b45-710f95f0a888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 스케일링\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "# PCA의 feature 수를 결정하는 변수\n",
    "feature_cnt = 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cdf6817-8aff-4329-b28c-640fe8d496c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pca 사용 차원 축소\n",
    "pca = PCA(n_components=feature_cnt)\n",
    "X_pca = pca.fit_transform(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1206602a-8d96-48b5-98b2-7336cece3873",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_original = pca.inverse_transform(X_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7bbb979-1ec2-4434-a533-af4422dfd3eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 0.0538720301459142\n"
     ]
    }
   ],
   "source": [
    "mse = mean_squared_error(X_original, X_scaled)\n",
    "print(\"Mean Squared Error (MSE):\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18fc33a7-9bb9-4a1a-a6de-d10d28213c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstruction Rate: 0.9430605247256114\n"
     ]
    }
   ],
   "source": [
    "# 복원률 계산\n",
    "reconstruction_rate = 1 - (mse / (X_original ** 2).mean())\n",
    "print(\"Reconstruction Rate:\", reconstruction_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18c79f4-0202-451a-a558-01e2e44b83ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
