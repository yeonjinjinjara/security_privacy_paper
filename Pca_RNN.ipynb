{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b97a345-86bc-4ffd-8d1f-91f8f9d8d023",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense, Input\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.decomposition import PCA\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "976ef0e7-ccc4-412e-baad-148ecc0e31ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_dataset(files, col_names, processed = False):\n",
    "\tdtypes = {}\n",
    "\tif processed == False:\n",
    "\t\tfor col_name in col_names:\n",
    "\t\t\tnominal_names = set(['srcip', 'sport', 'dstip', 'dsport', 'proto', 'state',\n",
    "\t\t\t\t                 'service', 'ct_ftp', 'label_10'])  #Nominal column\n",
    "\t\t\tif col_name in nominal_names:\n",
    "\t\t\t\tdtypes[col_name] =  str\n",
    "\t\t\telse:\n",
    "\t\t\t\tdtypes[col_name] = np.float32\n",
    "\telse:\n",
    "\t\tfor col_name in col_names:\n",
    "\t\t\tdtypes[col_name] = np.float32\n",
    "\n",
    "\trecords = []\n",
    "\tfor file in files:\n",
    "\t\tdata = pd.read_csv(file, header = None, names = col_names, dtype = dtypes)\n",
    "\t\trecords.append(data)\n",
    "\n",
    "\trecords_all = pd.concat(records) #When there is no index, concat adds them together regardless of the column names,\n",
    "\n",
    "\n",
    "\treturn records_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97a0e73f-8adf-4fb7-bde9-9fdadc7b970b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove the unimportant feature, one-hot encoding, and convert the attack class to numeric\n",
    "def select_feature_and_encoding(dataset, cols_to_drop, cols_nominal):\n",
    "    \n",
    "\t# Drop the features has no meaning such as src ip.\n",
    "    for cols in cols_to_drop:\n",
    "        dataset.drop(cols, axis = 1, inplace = True)\n",
    "\n",
    "\t# Save the label and then drop it from dataset\n",
    "    label_10 = dataset['label_10']\n",
    "    dataset.drop('label_2', axis = 1, inplace = True)\n",
    "\n",
    "\t# replace the label with specific code\n",
    "    replace_dict = { 'NaN': 0, 'Analysis': 1, 'Backdoors': 2, 'Backdoor': 2, 'DoS': 3,\n",
    "                    'Exploits':4,' Fuzzers': 5, ' Fuzzers ':5, 'Generic': 6,\n",
    "                    'Reconnaissance': 7, ' Shellcode ':8, 'Shellcode': 8,\n",
    "                    'Worms':9, ' Reconnaissance ': 7,}\n",
    "    dataset['label_10'] = label_10.replace(replace_dict)\n",
    "\n",
    "\t# replace the lost values\n",
    "    replace_dict = {\"NaN\": 0, ' ': 0}\n",
    "    for cols in ['ct_ftp', 'ct_flw', 'is_ftp']:\n",
    "        dataset[cols] = dataset[cols].replace(replace_dict)\n",
    "        \n",
    "    for x in dataset['is_ftp']:\n",
    "        if x != 0:\n",
    "            x = 1\n",
    "\n",
    "    for col_name in cols_nominal:\n",
    "        dataset.drop(col_name, axis = 1, inplace = True) \n",
    "\n",
    "    return dataset  #Complete data set (including data and labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2ce4b1b-a45c-4200-a1e2-2768605629d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_folder = 'unsw-NB15/'  #The location where the original file was read\n",
    "col_names = ['srcip', 'sport', 'dstip', 'dsport', 'proto', 'state', 'dur',\n",
    "\t             'sbytes', 'dbytes', 'sttl', 'dttl', 'sloss', 'dloss',\n",
    "\t             'service', 'sload', 'dload', 'spkts', 'dpkts', 'swin', 'dwin',\n",
    "\t             'stcpb', 'dtcpb', 'smeansz', 'dmeansz', 'trans_depth',\n",
    "\t             'res_bdy_len', 'sjit', 'djit', 'stime', 'ltime', 'sintpkt',\n",
    "\t             'dintpkt', 'tcprtt', 'synack', 'ackdat', 'is_sm_ips',\n",
    "\t             'ct_state_ttl', 'ct_flw', 'is_ftp', 'ct_ftp', 'ct_srv_src',\n",
    "\t             'ct_srv_dst', 'ct_dst_ltm', 'ct_src_ltm', 'ct_src_dport',\n",
    "\t             'ct_dst_sport', 'ct_dst_src', 'label_10', 'label_2']    #listed name\n",
    "\n",
    "cols_to_drop = ['srcip', 'dstip', 'stime', 'ltime', 'sport', 'dsport']\n",
    "cols_nominal = ['proto', 'service', 'state']   #Nominal features\n",
    "\n",
    "files = [file_folder + 'UNSW-NB15_' + str(i+1) + '.csv' for i in range(4)]\n",
    "dataset = combine_dataset(files, col_names)\n",
    "dataset = dataset.fillna(\"NaN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3215987b-666e-4511-be59-c03b5c1ab2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = select_feature_and_encoding(dataset, cols_to_drop, cols_nominal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71eba56a-3626-4d86-9586-d88b53435a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.drop('label_10', axis=1)\n",
    "y = dataset['label_10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "125e4d97-f4ed-4ab6-8df8-1f04a82b89b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 스케일링\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "# feature 수를 결정하는 변수\n",
    "feature_cnt = 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd34e486-b152-4af6-8c1b-fa2d629a3a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pca 사용 차원 축소\n",
    "pca = PCA(n_components=feature_cnt)\n",
    "X_pca = pca.fit_transform(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8eb3f1c-ce31-455a-9dd1-d29d78219560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분류 라벨을 원-핫 인코딩\n",
    "y_onehot = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e8befaf-a0c9-4cce-bf29-a2f6c4d30dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM 입력 형태로 데이터 재구성\n",
    "X_reshaped = X_pca.reshape(X_pca.shape[0], X_pca.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "879e8832-fa54-4164-8fd1-87f5ce8a0da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터와 테스트 데이터로 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reshaped, y_onehot, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c17dfa7-3543-4e37-a79d-85d8278b30a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\duswl\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# RNN 모델 정의\n",
    "model = Sequential([\n",
    "    SimpleRNN(64, input_shape=(X_train.shape[1], X_train.shape[2]), activation='relu', return_sequences=True),\n",
    "    SimpleRNN(32, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "638372c1-d7bd-4575-aced-26cf83d10ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65b12220-c343-4dcf-b592-47963fa020dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m28576/28576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 3ms/step - accuracy: 0.9616 - loss: 0.1196 - val_accuracy: 0.9707 - val_loss: 0.0768\n",
      "Epoch 2/10\n",
      "\u001b[1m28576/28576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 3ms/step - accuracy: 0.9712 - loss: 0.0766 - val_accuracy: 0.9721 - val_loss: 0.0735\n",
      "Epoch 3/10\n",
      "\u001b[1m28576/28576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 3ms/step - accuracy: 0.9717 - loss: 0.0749 - val_accuracy: 0.9716 - val_loss: 0.0728\n",
      "Epoch 4/10\n",
      "\u001b[1m28576/28576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 3ms/step - accuracy: 0.9723 - loss: 0.0731 - val_accuracy: 0.9725 - val_loss: 0.0741\n",
      "Epoch 5/10\n",
      "\u001b[1m28576/28576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 3ms/step - accuracy: 0.9727 - loss: 0.0719 - val_accuracy: 0.9724 - val_loss: 0.0723\n",
      "Epoch 6/10\n",
      "\u001b[1m28576/28576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 3ms/step - accuracy: 0.9723 - loss: 0.0732 - val_accuracy: 0.9717 - val_loss: 0.0745\n",
      "Epoch 7/10\n",
      "\u001b[1m28576/28576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 3ms/step - accuracy: 0.9728 - loss: 0.0802 - val_accuracy: 0.9707 - val_loss: 0.0754\n",
      "Epoch 8/10\n",
      "\u001b[1m28576/28576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 3ms/step - accuracy: 0.9727 - loss: 0.0721 - val_accuracy: 0.9723 - val_loss: 0.0726\n",
      "Training Time: 614.5757098197937 seconds\n"
     ]
    }
   ],
   "source": [
    "# RNN 모델 학습\n",
    "start_time = time.time()\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=64, validation_split=0.1, callbacks=[EarlyStopping(patience=3)])\n",
    "training_time = time.time() - start_time\n",
    "print(\"Training Time:\", training_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "05e434c5-2ba2-40a5-99ff-9e45e5eb7389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15876/15876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - accuracy: 0.9729 - loss: 0.0713\n",
      "Test Loss: 0.07157134264707565\n",
      "Test Accuracy: 0.9726954102516174\n",
      "Testing Time: 16.02929949760437 seconds\n"
     ]
    }
   ],
   "source": [
    "# 모델 평가\n",
    "start_time = time.time()\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "inference_time = time.time() - start_time  # 예측 시간 측정 종료\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "print(\"Testing Time:\", inference_time, \"seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
